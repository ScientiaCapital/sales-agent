from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from app.services.langchain.cerebras_llm import CerebrasLLM
from app.services.langgraph.tools import {{ tools }}

class {{ class_name }}:
    """{{ description }}"""
    
    def __init__(self):
        self.llm = CerebrasLLM(
            model="llama3.1-8b",
            temperature=0.7,
            max_tokens=500
        )
        self.tools = {{ tools }}
        
    def create_chain(self):
        """Create LCEL chain for {{ name }}."""
        prompt = """{{ prompt_template }}"""
        
        chain = (
            RunnablePassthrough()
            | prompt
            | self.llm
            | StrOutputParser()
        )
        
        return chain
    
    async def execute(self, input_data: dict) -> dict:
        """Execute {{ name }} agent."""
        chain = self.create_chain()
        result = await chain.ainvoke(input_data)
        
        return {
            "result": result,
            "agent_type": "{{ name }}",
            "status": "completed"
        }